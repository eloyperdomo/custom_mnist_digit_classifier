{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST_withCustomLearner2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_x95SvF9tCqz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x95SvF9tCqz"
      },
      "source": [
        "# Learner class (Mnist Dataset)\n",
        "\n",
        "In this notebook I will use SGD to optimize a model able to classify digits in public dataset (MNIST).\n",
        "Also, I will create my own implementation of fastai Learner class. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLLdSKXaf30H"
      },
      "source": [
        "# Import fastai\n",
        "This will give me access to some pytorch functions that I will use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UgpXo9TKXO7",
        "outputId": "bedfa83f-88e0-465e-81ab-39e435ebf1f7"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 6.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 20.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 18.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[K     |████████████████████████████████| 12.8MB 236kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YZgkF9NYgK"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from fastbook import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuZYbJgStsVE"
      },
      "source": [
        "## Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aYNDd6gZGJl"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6TvvOIvZJQJ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8c50ea6b-f214-442f-b4f3-56dfc0fe7835"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65ee4705-3688-4c8c-87ac-6f0a359018c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-65ee4705-3688-4c8c-87ac-6f0a359018c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mnist-original.mat to mnist-original.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjMAJqabYbMs"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "mnist = loadmat(\"mnist-original.mat\")\n",
        "data = mnist[\"data\"].T\n",
        "label = mnist[\"label\"][0]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaWuDsFBgCs7"
      },
      "source": [
        "Let's look at the shape of data and label and some examples to check what kind of data I am going to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvIA_rKLdIX8",
        "outputId": "155562e3-a2be-4c00-a907-11e88e75eb54"
      },
      "source": [
        "data.shape, label.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70000, 784), (70000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzvwlulcf0Dh",
        "outputId": "2174b8ed-0e02-4ac1-ec60-97bd8cb98ffa"
      },
      "source": [
        "28*28"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju6uW8YBgYY4"
      },
      "source": [
        "Okey, so it seems that data is composed by 28*28 images with all the pixels combined into a single numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mhKSolDe7Xj",
        "outputId": "4528e9b6-4756-4e0a-d384-3c3410a5af1a"
      },
      "source": [
        "data[69990]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,  66, 148, 230, 254, 203,  83,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,  93, 231, 253, 246, 192, 168, 222, 164,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  45,\n",
              "       196, 253, 217, 103,  28,   0,   0,  33,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5, 119, 246, 242, 127,   8,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 180, 253, 202,  49,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0, 153, 255, 169,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  49, 249, 218,  18,  15,  62, 105,\n",
              "       187, 226,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  30, 232, 254, 253, 253, 253, 253, 254, 230,  28,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31,  65, 108, 138,  57, 214, 249,  91,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 211, 223,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 254, 129,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193, 249,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  80, 250, 113,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  14, 215, 207,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 125, 253,  76,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 246, 134,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 219, 221,  22,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  52, 254,\n",
              "        98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19, 224, 178,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 157, 253,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDdCi8pmidIb"
      },
      "source": [
        "All pixels of the images are numbers between 0 and 255. I will convert them to floating point numbers between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q45hMvcitbU"
      },
      "source": [
        "data = [data[i]/255 for i in range(len(data))]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owrJJ_d2jVn3"
      },
      "source": [
        "Now I will check the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpWP3wxxYa2n",
        "outputId": "72dcde20-0525-42a0-d99d-182b3afe0982"
      },
      "source": [
        "label[69990]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh_TjGj5grQh"
      },
      "source": [
        "Let's visualize the example before in a more user friendly way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "l1iYqbAdkgLn",
        "outputId": "aa456a45-b252-4275-d2ce-80bfc23cca85"
      },
      "source": [
        "Image.fromarray((data[69990]*255).astype(\"uint8\").reshape((28,28))).resize((100,100))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAGpUlEQVR4nO3Z15IbxxUA0O7JPRmDHJbARlArscrS//+Bq1wKFrlLEDkP0gQAk6f9ILksEbTRs6Bf7L2v24NTt8PtsAC8xmu8xmu8xmu8xmv83we86GMIIYQUhBBCADDGOE1xivFXRQDPCwJCEhJYhsJx6B/37tELovSzZswlBo00zTCMYl4XBSb199Z6PjN3VvI1EU41jGKlXK5XCorIpJ69nvUEGgfe5w1fhtAMyyNR1nNGoVTKl/I6YgGQRMTEQRQ4dPRVEEbVi7WyoSuqpimiwCZHiAFNy4UgjI9r86T5ixCpWLt9e1tSBZ7naewfbT+KKFnjWa10WIvUxQiEkNFKjWb7u/uCAAHAUWBv7b0X0npJxRHFcczJjM2KQF7R9UK1UW+1iig+HHzv4G539tGPaL2o08lh7QSfT67MCCXXb1r1aiVvqMxhPTe3O8u23WMYpZSSU3kmPSz2lyKsVGy9+/aqlEN0vF8Pu6OFubEPfphiQCFZFhAXW25yAUIzLFKN+tv2XUXh8MFazwe98WK1c4Lf/m7zoiAK8Ohdkgmr54q1RqN5U0PJxjank4W5XFvOPvhngyANAw5GF42JVLlqtW9reZ33N9PxoDtceUc/iOJ/tUiC2AdpfFIgyRG1/Obu/vGuyAJvN+l0O53h7vMmaRp/6UtShFW1UvP+unVlsJ5lzgbd4XB+YvzbIESExl2r1aoVdGjPur3JbL7ausQGKaJef99uVjU+ccynn95PN84x+rwKXoZAmmHq1w/3VZ2J7Pno+fl54YTkAhlCaYb+bfu6qmB3M+z0u93F7mS5XYwwxm3zsV3XUscc/PpLf2nZGQ0SRCjcPD60DM5eDp5++nl0SE/WwaUIpBi13Lxp5NjA7L5//jh2AKAZhmYYjmUYGkdHL4jiM6mdQSDNSoVas1VA4arz1x/7UxsAWkI8LyqaKsk8tmezrXMuuXOZUKycL9crImNvhu9/XkQA8KomiZJaKJdyhpzM3jMgDoP//CME3SXIqkqDNIoSwHEISZomS6JeqlSMghyh7Yijzx3eziE4STFkaADkwo2t7SFCoiwjjhN1w1ANLkIw9IJzs+0cksRBEIQAAL7OlDchYFhO4GkAGB4hngNpsLftQ3Rmvp1D0jg4upatAcBdVWKMIaAoCDDGFAUBwK5lWY53aSY4DfdmX8wzNMNxDEvBNPJiiudpAAAO3Pli4/qnG0hGBKThrsetdJ5DooQEnk7s9VEoVnMIgHgz7Xdm7rnOOotgACKr53YVAUmSIksSF89HtvrwHTYQ8JYfn56n7pc3qkyZ4OQQOzMBiZKsyLLCx5PersBW8goC/mbQGa5Pzw3ZEQBSLzxwvICQhESRi82JE1t+nOI0sObjlUuwrxBtWglO4+DAsSzL0alreWIQY5zGvm3Od/75RMgQiJM0/O3eBkASJwmgII78vbXdHElqMhGCwZ9+ieYEgQe+td3Zp0fSFyN/DlbKGTmZ2pvzzZHIACd3ibPBKcVqpaBS9nSyOVN9X4zQYq5aL+so3k4mG/+/hGBUajYrCvCWvcH65Ar65cg8Jliu39/VZbCfdHo7wkwyI7Rav20VIN5O+6P4fEV5AQIhJRm1RpEL7eVydSD9LCPCCvlytSL7u1l/RTggmREG6ZVaxeDW3W53S7ZGAMg6u1ileFUtSHjbfxpY5Ge8bIhQaN7UVcpbjfszh3DUQdbuQtW37TdSuJsPh+aBvLsyIVBpPLTLjGvOpjPn5FXrqyAUJeVrzRryV7P5apflhkKOQEEqXl1VDX/T607tTLcg8oGHUuX6plFA/uTpeUq8DjMirFa/bZZQYo07PZOwaP0exN0FhXzzriEFzmw8XmTrLXKEEst335Rpc93pT3ce+RrJgkBeq93dC/Z48DQ09zH59M2AsChXb9RL0Wzc6S/sbHkQI1Kt1b4rcofVsDuxshrELxL3P7TbWrSd9nrzY1aDFNFvf3gocs5iPJruMidCeIKk1cqbOrs3s9aT34NoMUIkG3kpMXv9ecZXFXIEcqqmIOCOnj8tyffcPwTJ2wqvVosKnWzH3RHpcS4zwhWvbm70xF6MBlnrCTkiXH3/eK0fneFgtD1kfSAiRdTmX94Z1HbaH829jPWEEGEYuXZ9f02Zk0+DpZ35EYoIgUqp9s2727yz+OVDd/dC4yyiXz8+vq0Cr/+3v9vOC42ziJCvlVUAlr0PH7O/2BEiIHTXErNOf/20zF6ySBHsDPy+IaXzD/uXG2f/mckJAscywHf3F2TyvxP/ADleGlzb/Ry3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100 at 0x7FAC9B2A9090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9SqzKlAwyvt"
      },
      "source": [
        "To be able to make the neural network I will transform each array into a tensor.\n",
        "\n",
        "And each label into an integer.\n",
        "<!-- and each label into a hot encoded vector (this will allow me to make a nice loss function). -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wFS4B2owzrq"
      },
      "source": [
        "data = [tensor(data[i]) for i in range(len(data))]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8-vJOHXqNfU"
      },
      "source": [
        "label = [int(label[i]) for i in range(len(label))]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz55fL5rty_f"
      },
      "source": [
        "## Creating the Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2C0zgzLuQQm"
      },
      "source": [
        "### Datasets\n",
        "\n",
        "First, I will create a dataset (something that if I index on it I will get a pair of a dependent and independent variable) and split into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2kcx5gonUss"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSjpILSrn8P9"
      },
      "source": [
        "dset = list(zip(data,label))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxY_-Gh2nYfl"
      },
      "source": [
        "train_dset, valid_dset = train_test_split(dset, test_size = 0.15, random_state = 999)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHmcJx3qCdy",
        "outputId": "a0c9554d-4a65-4dbc-bf1f-fef2c478e43a"
      },
      "source": [
        "len(train_dset), len(valid_dset)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59500, 10500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB5r95_2uU4n"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Then I will pass the datasets to a DataLoader object, which basically combines them into groups (mini-batchs) of certain size (batch_size) randomly (shuffle=True) to pass them at the same time to the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oYN4cO7Uv32"
      },
      "source": [
        "train_dl = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256, shuffle=True)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt3SNeWBuXas"
      },
      "source": [
        "### Dataloaders\n",
        "Now I will combine the training and validation dataloaders into a DataLoaders object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWv3HMhCV9GV"
      },
      "source": [
        "dls = DataLoaders(train_dl, valid_dl)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zuk6lBfanis"
      },
      "source": [
        "Before starting to work with the Dataloaders I will use some samples of the train dataset to create a model, a loss function and a metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoIOYjZLa4xM"
      },
      "source": [
        "# Model\n",
        "Because my independent variable are 28\\*28 numbers and my dependent variable is an integer from 0 to 9, I will create a simple linear model using pytorch class nn.Linear with 28\\*28 inputs and 10 outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "443kLelGaU6o"
      },
      "source": [
        "model0 = nn.Linear(28*28, 10)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97zV_XubX9u"
      },
      "source": [
        "I will extract one independent and its dependet variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-BSRppxaI5L",
        "outputId": "9bfa6bfe-227e-4f57-ecc7-6c698e677610"
      },
      "source": [
        "x0 = train_dset[0][0]\n",
        "y0 = train_dset[0][1]\n",
        "y0"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uymQ7Mnmbj6u"
      },
      "source": [
        "So the model outputs a tensor of length ten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJa1KSEUaeq8",
        "outputId": "b5ad82a1-ca5c-43e5-fbff-8a9a07d21445"
      },
      "source": [
        "pred0 = model0(x0)\n",
        "pred0"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3654,  0.0556, -0.0160, -0.4832, -0.0369, -0.0733,  0.0502,  0.1787,  0.0399, -0.3788], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7eWLujxb7J3"
      },
      "source": [
        "Because the parameters of nn.Linear are initialized randomly this results doesn't mean anything, but I can start adjusting the parameters to make the result what I want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H7KUMvJrclX"
      },
      "source": [
        "# Loss function and metric\n",
        "To adjust the parameters I will create a loss function that will allow me to check how far I am from the correct predictions to adjust the parameters based on this. Also, I will create a metric, which is basically the score that I care about.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4eZnZCmssxj"
      },
      "source": [
        "## Loss function\n",
        "The loss function should change for every small change that I will make to the parameters (weights), so I can calculate the gradients of the parameters based on this function and then change the parameters using the gradients to minimize it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqauN2mOllEv"
      },
      "source": [
        "I want my vector of predictions to be numbers between 0 and 1 that add up to 1, so I will use softmax  for this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CQ8HZkoJcSJ"
      },
      "source": [
        "I will get a subset of the data to do some tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y-U4j8jF0bu",
        "outputId": "dab5acee-7c10-4ac7-e2e2-b6120d55f7d9"
      },
      "source": [
        "b0 = [train_dset[i] for i in [1,1000,10000,20000,40000]]\n",
        "y0 = tensor([b0[i][1] for i in range(len(b0))])\n",
        "y0"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7, 1, 0, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9gzJITQJTCd"
      },
      "source": [
        "Let`s get some random predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOBC6YnrGcLn",
        "outputId": "913eb7ff-451f-42a1-f732-6bd391f7504f"
      },
      "source": [
        "preds0 = [model0(b0[i][0]) for i in range(len(b0))]\n",
        "preds0 = torch.reshape(torch.cat(preds0), [5, 10])\n",
        "preds0"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0300,  0.1283, -0.3694, -0.4504,  0.1765,  0.0037,  0.2613, -0.0500, -0.1676, -0.1789],\n",
              "        [ 0.0719,  0.2860, -0.4811, -0.1513, -0.0363, -0.1496,  0.2098, -0.0237,  0.0428, -0.0260],\n",
              "        [ 0.0566,  0.1351,  0.1062, -0.0830, -0.3586,  0.2543, -0.0774, -0.0118,  0.1909, -0.1278],\n",
              "        [ 0.5476,  0.1255, -0.0127, -0.0042, -0.0626,  0.2046,  0.1181,  0.1144,  0.1591,  0.1332],\n",
              "        [ 0.1094, -0.0568,  0.1931, -0.1870, -0.1404,  0.0061, -0.0195,  0.0705, -0.1190, -0.0589]], grad_fn=<ViewBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9EVYQHEJ3JG"
      },
      "source": [
        "Now I apply softmax to see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBvXbLRpIh0j",
        "outputId": "7e335451-ca83-4a9e-cbfb-f77abc229b2f"
      },
      "source": [
        "preds0_sm = torch.softmax(preds0, dim=-1)\n",
        "preds0_sm"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1071, 0.1181, 0.0718, 0.0662, 0.1240, 0.1043, 0.1349, 0.0988, 0.0879, 0.0869],\n",
              "        [0.1081, 0.1340, 0.0622, 0.0865, 0.0970, 0.0867, 0.1241, 0.0983, 0.1050, 0.0981],\n",
              "        [0.1035, 0.1119, 0.1087, 0.0900, 0.0683, 0.1261, 0.0905, 0.0966, 0.1183, 0.0860],\n",
              "        [0.1494, 0.0980, 0.0853, 0.0860, 0.0812, 0.1060, 0.0972, 0.0969, 0.1013, 0.0987],\n",
              "        [0.1131, 0.0958, 0.1230, 0.0841, 0.0881, 0.1020, 0.0994, 0.1088, 0.0900, 0.0956]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RSBWzJ6mT02"
      },
      "source": [
        "From this vector, I will index to get the probability of the correct prediction and I will multiply this by -1. \n",
        "\n",
        "So the result will be smaller as the prediction for the correct target is bigger.\n",
        "\n",
        "To do this I will use negative log likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9xzEdH8m9yz",
        "outputId": "f5ca4984-cb1c-4f85-ac01-66376cbfeae0"
      },
      "source": [
        "idx = range(len(preds0_sm))\n",
        "-preds0_sm[idx, y0]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0988, -0.0983, -0.1119, -0.1494, -0.1088], grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwrsXrmHK8DB",
        "outputId": "2a0da0e8-b3df-4655-f6e7-8205c37eeecd"
      },
      "source": [
        "preds0_sm_nll = F.nll_loss(preds0_sm, y0, reduction='none')\n",
        "preds0_sm_nll"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0988, -0.0983, -0.1119, -0.1494, -0.1088], grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvY-SNJuLaVF"
      },
      "source": [
        "In nll_loss the logarithm wasn't apply. This is due to the fact that nll_loss assumes that you already applied the log because for computational reasons is better to do it before. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wO4Qal6oPc8"
      },
      "source": [
        "The combination of this two methods in called Cross Entropy Loss (log_softmax + nll_loss). So I will directly use the function available for this in pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19qQtH7fM2zT",
        "outputId": "cd307750-8ef0-4718-fee6-1267340c6037"
      },
      "source": [
        "F.nll_loss(F.log_softmax(preds0), y0)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.1887, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HQNqqEYryHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7c9a90-a365-42c1-f984-00e18fee76ce"
      },
      "source": [
        "F.cross_entropy(preds0, y0)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.1887, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgLmgU4asv2u"
      },
      "source": [
        "## Metric\n",
        "The metric will be something more interpretable like what percentage of the predictions are correct.\n",
        "\n",
        "In this case I will use softmax again to make all the values between 0 and 1 and adding up to 1. Then I will select the index of the biggest value for each prediction tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHr526A7T6F_"
      },
      "source": [
        "def mnist_accuracy(input, targets, axis=-1):\n",
        "  sm = torch.softmax(input,dim=axis)\n",
        "  preds = sm.argmax(dim=axis)\n",
        "  return(preds==targets).float().mean()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loFYkb-gUqFY",
        "outputId": "a58b4fd0-415c-4bd9-d40b-ffe6117aac37"
      },
      "source": [
        "mnist_accuracy(preds0, y0)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgApvq72d4tw"
      },
      "source": [
        "def epoch_accuracy(model, valid_data_loader):\n",
        "  \"\"\"Function that applies mnist_accuracy to every batch of\n",
        "  the validation data laoder and take the mean\"\"\"\n",
        "  return np.mean([mnist_accuracy(model(xb), yb) for xb,yb in valid_data_loader])\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xkfs2_6RdwE"
      },
      "source": [
        "# Putting all together\n",
        "Now I have the data, a model, a loss function and a metric. I will combine all this to create a trainning cycle.\n",
        "\n",
        "Every batch I will adjust the parameters of the model based on the gradients of this parameters from the loss function (SGD)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR8PAXCSWTIx",
        "outputId": "1107f57d-2a53-4614-b7d2-7c860561f116"
      },
      "source": [
        "print(\"Accuracy before training: \", epoch_accuracy(model0, valid_dl))\n",
        "\n",
        "for xb,yb in train_dl:\n",
        "  loss = F.cross_entropy(model0(xb), yb)\n",
        "  loss.backward()\n",
        "  for p in model0.parameters():\n",
        "    # I will use a learning rate of 1\n",
        "    p.data -= p.grad * 1\n",
        "    p.grad.zero_()\n",
        "\n",
        "print(\"Accuracy first epoch: \", epoch_accuracy(model0, valid_dl))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy before training:  0.11309524\n",
            "Accuracy first epoch:  0.8966704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARRX6P-UWTBE"
      },
      "source": [
        "After just one epoch I go from around 13% accuracy on the validation set to around 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mStO6ErFfsOQ"
      },
      "source": [
        "I will predict one random item from the validation set and compare to its label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UiZ1EVkWS5T",
        "outputId": "5acd3309-449e-4141-a48a-22dac2f25a9d"
      },
      "source": [
        "sm = torch.softmax(model0(valid_dset[10000][0]),dim=-1)\n",
        "sm.argmax(dim=-1), valid_dset[10000][1]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9), 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LM1MASbfE8h"
      },
      "source": [
        "This looks good!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFx3tbiHfF_A"
      },
      "source": [
        "#Learner class\n",
        "Lastly, I will create my own implementation of fastai Learner class, which will allow me to pass the data, model, etc and then use everything as a whole much easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7I6H1-JVScE"
      },
      "source": [
        "class learner2():\n",
        "  def __init__(self,dataloaders, model, opt_func, loss_func, metrics, lr=1):\n",
        "    self.train = dataloaders[0]\n",
        "    self.valid = dataloaders[1]\n",
        "    self.model = model\n",
        "    self.opt_func = opt_func\n",
        "    self.loss_func = loss_func\n",
        "    self.metrics = metrics\n",
        "    self.lr = lr\n",
        "    self.opt = None\n",
        "    self.loss = None\n",
        "  \n",
        "  def create_opt(self):\n",
        "        self.opt = self.opt_func(self.model.parameters(), lr=self.lr)\n",
        "      \n",
        "  def calc_grad(self, xb, yb):\n",
        "    preds = self.model(xb)\n",
        "    self.loss = self.loss_func(preds, yb)\n",
        "    self.loss.backward()\n",
        "      \n",
        "  def validate_epoch(self):\n",
        "    accs = [self.metrics(self.model(xb), yb) for xb,yb in self.valid]\n",
        "    return round(torch.stack(accs).mean().item(), 4)\n",
        "  \n",
        "  def fit(self, epochs, lr=None):\n",
        "    if lr:\n",
        "      self.lr = lr\n",
        "    if not self.opt: self.create_opt()\n",
        "    for i in range(epochs):\n",
        "      for xb,yb in self.train:\n",
        "        self.calc_grad(xb, yb)\n",
        "        self.opt.step()\n",
        "        self.opt.zero_grad()\n",
        "      print(\"Epoch \", i, \" \", self.metrics.__name__, \":\", self.validate_epoch(), end='\\n')\n",
        "  \n",
        "  def predict(self, x):\n",
        "    sm = torch.softmax(self.model(x),dim=-1)\n",
        "    return sm.argmax(dim=-1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR_si_RDpX5y"
      },
      "source": [
        "learn0 = learner2(dls, nn.Linear(28*28, 10), opt_func=SGD, loss_func=F.cross_entropy, metrics=mnist_accuracy)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHYxJJj5ppzc",
        "outputId": "b29e0be6-0942-4bc3-f6f4-0190622b7811"
      },
      "source": [
        "learn0.fit(10, lr=0.2)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0   mnist_accuracy : 0.8906\n",
            "Epoch  1   mnist_accuracy : 0.9047\n",
            "Epoch  2   mnist_accuracy : 0.9041\n",
            "Epoch  3   mnist_accuracy : 0.9124\n",
            "Epoch  4   mnist_accuracy : 0.914\n",
            "Epoch  5   mnist_accuracy : 0.9152\n",
            "Epoch  6   mnist_accuracy : 0.9107\n",
            "Epoch  7   mnist_accuracy : 0.9183\n",
            "Epoch  8   mnist_accuracy : 0.9178\n",
            "Epoch  9   mnist_accuracy : 0.9195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21uNycywiP9b",
        "outputId": "73f20d18-2203-42b5-97bc-39711972694c"
      },
      "source": [
        "learn0.predict(valid_dset[5478][0]), valid_dset[5478][1]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vObbD7Rbp1hx"
      },
      "source": [
        "So with a simple linear model using SGD I was able to achieve a 92% accuracy on validation set. To finish I will use a little more complex model (I will add a ReLU as activation function to make it non-linear).\n",
        "#Complex model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR0Tqt0NqFTU"
      },
      "source": [
        "model1 = nn.Sequential(\n",
        "    nn.Linear(28*28,50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50,10)\n",
        ")"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDy9xBYDqiAP"
      },
      "source": [
        "learn2 = learner2(dls, model1, opt_func=SGD, loss_func=F.cross_entropy, metrics=mnist_accuracy)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678hfQe4qvw6",
        "outputId": "fc0107bd-d723-40b0-a88c-02300e9558f7"
      },
      "source": [
        "learn2.fit(20,lr=0.4)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0   mnist_accuracy : 0.9181\n",
            "Epoch  1   mnist_accuracy : 0.9414\n",
            "Epoch  2   mnist_accuracy : 0.9433\n",
            "Epoch  3   mnist_accuracy : 0.9554\n",
            "Epoch  4   mnist_accuracy : 0.9612\n",
            "Epoch  5   mnist_accuracy : 0.963\n",
            "Epoch  6   mnist_accuracy : 0.9571\n",
            "Epoch  7   mnist_accuracy : 0.9644\n",
            "Epoch  8   mnist_accuracy : 0.966\n",
            "Epoch  9   mnist_accuracy : 0.9653\n",
            "Epoch  10   mnist_accuracy : 0.9698\n",
            "Epoch  11   mnist_accuracy : 0.9637\n",
            "Epoch  12   mnist_accuracy : 0.9707\n",
            "Epoch  13   mnist_accuracy : 0.9709\n",
            "Epoch  14   mnist_accuracy : 0.9717\n",
            "Epoch  15   mnist_accuracy : 0.9674\n",
            "Epoch  16   mnist_accuracy : 0.9643\n",
            "Epoch  17   mnist_accuracy : 0.972\n",
            "Epoch  18   mnist_accuracy : 0.973\n",
            "Epoch  19   mnist_accuracy : 0.972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIGJJhOjs9Cx",
        "outputId": "e8e02f86-41a2-4768-e38c-385268997d5c"
      },
      "source": [
        "learn2.fit(15,lr=0.02)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0   mnist_accuracy : 0.9705\n",
            "Epoch  1   mnist_accuracy : 0.9717\n",
            "Epoch  2   mnist_accuracy : 0.9713\n",
            "Epoch  3   mnist_accuracy : 0.9734\n",
            "Epoch  4   mnist_accuracy : 0.9682\n",
            "Epoch  5   mnist_accuracy : 0.9741\n",
            "Epoch  6   mnist_accuracy : 0.9719\n",
            "Epoch  7   mnist_accuracy : 0.9727\n",
            "Epoch  8   mnist_accuracy : 0.9677\n",
            "Epoch  9   mnist_accuracy : 0.9747\n",
            "Epoch  10   mnist_accuracy : 0.9739\n",
            "Epoch  11   mnist_accuracy : 0.973\n",
            "Epoch  12   mnist_accuracy : 0.9736\n",
            "Epoch  13   mnist_accuracy : 0.9735\n",
            "Epoch  14   mnist_accuracy : 0.9715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtknAbCPqv6D"
      },
      "source": [
        "I achieved 97% accuracy with this!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Nx26v-wcki"
      },
      "source": [
        "#Conclusion\n",
        "With very basic pytorch functions, using SGD I was able to develop a model that classifies digits with 92 % accuracy. Adding one extra layer made the model more complex, but in this case allowed me to reach a 97% accuracy.\n",
        "\n",
        "Also, I didn't spend much time tuning the learning rate or training the model, so with more time results could be even better."
      ]
    }
  ]
}
